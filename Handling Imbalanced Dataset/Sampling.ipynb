{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36032dd5",
   "metadata": {},
   "source": [
    "## Creating an Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee03527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578782ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023b1dd6",
   "metadata": {},
   "source": [
    "np.random.seed(0) forces NumPy‚Äôs random number generator to behave predictably.\n",
    "\n",
    "Think of the random generator like a shuffle machine.\n",
    "\n",
    "With a seed, you are giving it a fixed starting position.\n",
    "\n",
    "Without a seed, it starts in a random position every time.\n",
    "\n",
    "So np.random.seed(0) ensures:\n",
    "\n",
    "‚û° Every time you run the code\n",
    "‚û° You get THE EXACT SAME random numbers\n",
    "‚û° In the exact same order\n",
    "\n",
    "WITH seed:\n",
    "np.random.seed(0)\n",
    "print(np.random.rand(3))\n",
    "\n",
    "\n",
    "Output (always):\n",
    "\n",
    "[0.5488135  0.71518937 0.60276338]\n",
    "\n",
    "\n",
    "Run it 1000 times ‚Üí same result.\n",
    "\n",
    "WITHOUT seed:\n",
    "print(np.random.rand(3))\n",
    "\n",
    "\n",
    "Output changes EVERY run:\n",
    "\n",
    "[0.12 0.44 0.88]\n",
    "next run ‚Üí [0.77 0.21 0.95]\n",
    "next ‚Üí [0.34 0.56 0.10]\n",
    "\n",
    "\n",
    "Every execution = different numbers.\n",
    "\n",
    "üß† WHY do we even need a seed?\n",
    "\n",
    "Because ML and data science require reproducibility.\n",
    "If you generate random data or split a dataset and then:\n",
    "\n",
    "Someone else runs your code\n",
    "\n",
    "Or you run it after 1 month\n",
    "\n",
    "Or you debug your model\n",
    "\n",
    "‚Ä¶you want the EXACT same behavior.\n",
    "\n",
    "Otherwise:\n",
    "\n",
    "Your training accuracy changes\n",
    "\n",
    "Your dataset split changes\n",
    "\n",
    "Your results fluctuate\n",
    "\n",
    "You can't debug properly\n",
    "\n",
    "No one else can reproduce your project\n",
    "\n",
    "It becomes chaos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c2f3990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 100)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "ratio = 0.9\n",
    "n_class0 = int(n_samples * ratio)\n",
    "n_class1 = n_samples - n_class0\n",
    "\n",
    "\n",
    "n_class0, n_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a66af21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.186139</td>\n",
       "      <td>1.789128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.079940</td>\n",
       "      <td>1.987302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.128683</td>\n",
       "      <td>0.537318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.316058</td>\n",
       "      <td>1.612378</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.864886</td>\n",
       "      <td>0.812350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.513051</td>\n",
       "      <td>0.930543</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2.664769</td>\n",
       "      <td>0.968859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2.440069</td>\n",
       "      <td>-0.816291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2.485371</td>\n",
       "      <td>0.353901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.424903</td>\n",
       "      <td>-0.235946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature2  target\n",
       "0    0.186139  1.789128       0\n",
       "1    2.079940  1.987302       0\n",
       "2    2.128683  0.537318       0\n",
       "3    0.316058  1.612378       0\n",
       "4    0.864886  0.812350       0\n",
       "..        ...       ...     ...\n",
       "995  1.513051  0.930543       1\n",
       "996  2.664769  0.968859       1\n",
       "997  2.440069 -0.816291       1\n",
       "998  2.485371  0.353901       1\n",
       "999  0.424903 -0.235946       1\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroDf = pd.DataFrame({\n",
    "    'feature1' : np.random.normal(loc=1, scale=1, size=n_class0),\n",
    "    'feature2' : np.random.normal(loc=1, scale=1, size=n_class0),\n",
    "    'target' : [0]*n_class0 \n",
    "})\n",
    "\n",
    "oneDf = pd.DataFrame({\n",
    "    'feature1': np.random.normal(loc=1, scale=1, size=n_class1),\n",
    "    'feature2' : np.random.normal(loc=1, scale=1, size=n_class1),\n",
    "    'target' : [1]*n_class1\n",
    "})\n",
    "\n",
    "\n",
    "df = pd.concat([zeroDf, oneDf], ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586d16b",
   "metadata": {},
   "source": [
    "\n",
    "### **What `ignore_index=True` actually does**\n",
    "\n",
    "When you concatenate two DataFrames, Pandas normally **keeps their original row indexes**.\n",
    "\n",
    "Example:\n",
    "\n",
    "* `zeroDf` might have indexes `0,1,2,...,899`\n",
    "* `oneDf` might also have indexes `0,1,2,...,99`\n",
    "\n",
    "If you do:\n",
    "\n",
    "```python\n",
    "df = pd.concat([zeroDf, oneDf])\n",
    "```\n",
    "\n",
    "Your final DataFrame will have **duplicate indexes**, because both original DataFrames start at 0.\n",
    "\n",
    "Looks like this:\n",
    "\n",
    "```\n",
    "index | feature1 | feature2 | target\n",
    "0     | ...      | ...      | 0\n",
    "1     | ...      | ...      | 0\n",
    "...\n",
    "899   | ...      | ...      | 0\n",
    "0     | ...      | ...      | 1   ‚Üê duplicate index!\n",
    "1     | ...      | ...      | 1   ‚Üê duplicate index!\n",
    "...\n",
    "```\n",
    "\n",
    "This is messy and stupid for most use-cases.\n",
    "\n",
    "### **So what does `ignore_index=True` do?**\n",
    "\n",
    "It **throws away the original indexes**\n",
    "and creates a **fresh, clean, continuous index**:\n",
    "\n",
    "```\n",
    "index | feature1 | feature2 | target\n",
    "0     | ...      | ...      | 0\n",
    "1     | ...      | ...      | 0\n",
    "...\n",
    "999   | ...      | ...      | 1\n",
    "```\n",
    "\n",
    "That‚Äôs it. Nothing complicated.\n",
    "\n",
    "### **If you don‚Äôt use it?**\n",
    "\n",
    "You end up with **duplicate index values**, which can break:\n",
    "\n",
    "* row selection\n",
    "* merging\n",
    "* training ML models\n",
    "* debugging\n",
    "\n",
    "So it's safer to always use `ignore_index=True` when stacking rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c942a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    900\n",
       "1    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c915664",
   "metadata": {},
   "source": [
    "# Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b645e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority = df[df['target']==1]\n",
    "df_majority= df[df['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40e074d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01f5fa57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    900\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_minority_upsampled = resample(\n",
    "    df_minority,\n",
    "    replace=True,\n",
    "    n_samples=len(df_majority),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_minority_upsampled['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1d68357",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_df = pd.concat([df_majority, df_minority_upsampled], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "705c1c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    900\n",
       "1    900\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab8cdf3",
   "metadata": {},
   "source": [
    "## DownSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e187d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    900\n",
       "1    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67c67021",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority = df[df['target']==1]\n",
    "df_majority= df[df['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c557227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority_downsampled = resample(\n",
    "    df_majority,\n",
    "    replace=False,\n",
    "    n_samples=len(df_minority),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_majority_downsampled['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c57286b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    100\n",
       "0    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled_df = pd.concat([df_minority, df_majority_downsampled], ignore_index=True)\n",
    "downsampled_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51376e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
